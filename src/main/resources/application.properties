spring.application.name=springai


spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=gemma2:9b
spring.ai.ollama.init.max-retries = 1
spring.ai.ollama.chat.enabled=true
spring.ai.chat.observations.include-prompt=true
spring.ai.chat.observations.include-error-logging=true

management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://localhost:3000/api/public/otel/v1/traces
management.observations.annotations.enabled=true
# this is key is as per my local running of langfuse. Will not work anywher else
management.otlp.tracing.headers.Authorization=Basic cGstbGYtYTY0N2NiNjAtOGI2ZC00MWQ1LWI1MTMtZTQwN2Q4NWI3ODc0OnNrLWxmLTZmZDNlZmMwLWI1MGQtNGJkMC04YzVhLTI5YTZjZDA2MTFkNQ==